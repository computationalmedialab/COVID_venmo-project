{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import requests\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = psycopg2.connect(\n",
    "        user=\"postgres\",\n",
    "        password=os.environ.get(\"POSTGRES_PASS\", \"\"),\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"venmo\",\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/openeventdata/mordecai\n",
    "#  $ python -m spacy download en_core_web_lg\n",
    "#  $ docker pull elasticsearch:5.5.2\n",
    "#  $ wget https://andrewhalterman.com/files/geonames_index.tar.gz\n",
    "#  $ docker run -d -p 127.0.0.1:9200:9200 -v $(pwd)/geonames_index/:/usr/share/elasticsearch/data elasticsearch:5.5.2\n",
    "from mordecai import Geoparser\n",
    "\n",
    "# https://github.com/somnathrakshit/geograpy3\n",
    "#  > This wasn't very good.\n",
    "# import geograpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = Geoparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mordecai_tokens = Counter()\n",
    "mordecai_token_examples = defaultdict(list)\n",
    "meta = Counter()\n",
    "\n",
    "conn = connect()\n",
    "with conn.cursor(name=\"exploration\") as cursor:\n",
    "    cursor.itersize = 2000\n",
    "    cursor.execute(\"SELECT * FROM transactions\")\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i % 10000 == 0 and i != 0:\n",
    "            # checkpoint\n",
    "            print(\"Checkpoint\", i)\n",
    "            with open(\"mordecai_tokens.pkl\", \"wb\") as f:\n",
    "                pickle.dump((mordecai_tokens, mordecai_token_examples), f)\n",
    "            with open(\"meta.pkl\", \"wb\") as f:\n",
    "                pickle.dump(meta, f)\n",
    "        raw_msg = row[1]\n",
    "        meta[\"msgs\"] += 1\n",
    "        if row[1] is None:\n",
    "            continue\n",
    "        msg = re.sub(r\"[^\\w\\d_\\- ]\", \"\", raw_msg).strip()\n",
    "        if len(msg) == 0:\n",
    "            continue\n",
    "        meta[\"msgs_processed\"] += 1\n",
    "\n",
    "        g = geo.geoparse(msg)\n",
    "        if len(g) != 0:\n",
    "            for w in [item[\"word\"] for item in g]:\n",
    "                mordecai_tokens[w] += 1\n",
    "                mordecai_token_examples[w].append(raw_msg)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "with open(\"mordecai_tokens.pkl\", \"rb\") as f:\n",
    "    mordecai_tokens_saved, mordecai_token_examples_saved = pickle.load(f)\n",
    "with open(\"meta.pkl\", \"rb\") as f:\n",
    "    meta_saved = pickle.load(f)\n",
    "meta_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 71%\n",
    "meta_saved[\"msgs_processed\"] / meta_saved[\"msgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1%\n",
    "sum(mordecai_tokens_saved.values()) / meta_saved[\"msgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_MORDECAI_TOKENS = {\n",
    "    \"Cali\": \"California\",\n",
    "    \"jersey\": \"Jersey\",\n",
    "    \"baja\": \"Baja\",\n",
    "    \"Vegas\": \"Las Vegas\",\n",
    "    \"vegas\": \"Las Vegas\",\n",
    "    \"VEGAS\": \"Las Vegas\",\n",
    "    \"NYC\": \"New York City\",\n",
    "    \"Nyc\": \"New York City\",\n",
    "    \"LA\": \"Los Angeles\",\n",
    "    \"Philly\": \"Philadelphia\",\n",
    "    \"Nola\": \"New Orleans\",\n",
    "}\n",
    "IGNORE_MORDECAI_TOKENS = set(\n",
    "    [\n",
    "        \"Wendys\",\n",
    "        \"Bc\",\n",
    "        \"Hookers\",\n",
    "        \"foooood\",\n",
    "        \"Santa\",\n",
    "        \"Easter\",\n",
    "        \"Playa\",\n",
    "        \"Yeehaw\",\n",
    "        \"Zelle\",\n",
    "        \"AZ\",\n",
    "        \"Tn\",\n",
    "        \"Anotha\",\n",
    "        \"Rv\",\n",
    "        \"RV\",\n",
    "        \"FL\",\n",
    "        \"NY\",\n",
    "        \"Sydney\",\n",
    "        \"Turkey\",\n",
    "        \"Brittany\",\n",
    "        \"Cleaning\",\n",
    "        \"Pussy\",\n",
    "        \"Daves\",\n",
    "        \"Charlotte\",\n",
    "        \"NC\",\n",
    "        \"Beach\",\n",
    "        \"China\",\n",
    "        \"Paris\",\n",
    "        \"Mexico\",\n",
    "        \"Iceland\",\n",
    "        \"Cancun\",\n",
    "        \"Canada\",\n",
    "        \"Thailand\",\n",
    "        \"Tokyo\",\n",
    "        \"India\",\n",
    "        \"Montreal\",\n",
    "        \"Oktoberfest\",\n",
    "        \"Burma\",\n",
    "        \"Nepal\",\n",
    "        \"Peru\",\n",
    "        \"Colombia\",\n",
    "        \"Italy\",\n",
    "        \"Bangkok\",\n",
    "        \"Moscow\",\n",
    "        \"Japan\",\n",
    "        \"Greece\",\n",
    "        \"Berlin\",\n",
    "        \"America\",\n",
    "        \"Amsterdam\",\n",
    "        \"London\",\n",
    "        \"Saigon\",\n",
    "        \"Brazil\",\n",
    "        \"Barcelona\",\n",
    "        \"Spain\",\n",
    "        \"Africa Join\",\n",
    "        \"Tulum\",\n",
    "        \"Kathmandu\",\n",
    "    ]\n",
    ")\n",
    "N = 50\n",
    "\n",
    "# Handle aliases\n",
    "for repl, token in REPLACE_MORDECAI_TOKENS.items():\n",
    "    if repl in mordecai_tokens_saved:\n",
    "        cnt = mordecai_tokens_saved[repl]\n",
    "        del mordecai_tokens_saved[repl]\n",
    "        mordecai_tokens_saved[token] += cnt\n",
    "\n",
    "tokens = []\n",
    "counts = []\n",
    "for token, cnt in mordecai_tokens_saved.most_common(N * 2):\n",
    "    if token in IGNORE_MORDECAI_TOKENS:\n",
    "        continue\n",
    "    tokens.append(token)\n",
    "    counts.append(cnt)\n",
    "    if len(tokens) == N:\n",
    "        break\n",
    "plt.figure(figsize=(15, N // 5))\n",
    "sns.barplot(y=tokens, x=counts, orient=\"h\").set_title(\n",
    "    \"Mordecai Keywords (of {} msgs)\".format(meta_saved[\"msgs\"])\n",
    ")\n",
    "# Tokens for other countries often used as adjective, \"China virus\" \"China town\" \"China food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = {\"token\": [], \"examples\": []}\n",
    "for token in tokens[:5]:\n",
    "    sample_usage = random.sample(mordecai_token_examples_saved[token], 5)\n",
    "    df_data[\"token\"].append(token)\n",
    "    df_data[\"examples\"].append(\"\\n\".join(sample_usage))\n",
    "df = pd.DataFrame(df_data)\n",
    "df.set_index(\"token\")\n",
    "\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
    "\n",
    "\n",
    "pretty_print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
