{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = psycopg2.connect(\n",
    "        user=\"postgres\",\n",
    "        password=os.environ.get(\"POSTGRES_PASS\", \"\"),\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"venmo\",\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partly from Machine Learning to Detect Self-Reporting of Symptoms, Testing Access, and Recovery Associated With COVID-19 on Twitter\n",
    "COVID_WORDS = [\n",
    "    \"diagnosed\",\n",
    "    \"pneumonia\",\n",
    "    \"coronavirus\",\n",
    "    \"fever\",\n",
    "    \"covid\",\n",
    "    \"isolating\",\n",
    "    \"quarantine\",\n",
    "    \"emergency room\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta = Counter()\n",
    "\n",
    "# Store timestamps\n",
    "covid_token_usage = {}\n",
    "covid_token_refs = {}\n",
    "for w in COVID_WORDS:\n",
    "    covid_token_usage[w] = []\n",
    "    covid_token_refs[w] = Counter()\n",
    "\n",
    "conn = connect()\n",
    "with conn.cursor(name=\"covid_exploration\") as cursor:\n",
    "    cursor.itersize = 2000\n",
    "    cursor.execute(\"SELECT * FROM transactions\")\n",
    "    for i, row in enumerate(cursor):\n",
    "\n",
    "        if i % 1_000_000 == 0:\n",
    "            # checkpoint\n",
    "            print(\"Row\", i)\n",
    "            with open(\"covid_tokens.pkl\", \"wb\") as f:\n",
    "                pickle.dump((covid_token_usage, covid_token_refs), f)\n",
    "            with open(\"covid_meta.pkl\", \"wb\") as f:\n",
    "                pickle.dump(meta, f)\n",
    "\n",
    "        msg = row[1]\n",
    "        try:\n",
    "            msg = re.sub(r\"[^\\w\\d_\\- ]\", \"\", msg).strip()\n",
    "            meta[\"msgs\"] += 1\n",
    "            if len(msg) == 0:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "        meta[\"msgs_processed\"] += 1\n",
    "\n",
    "        try:\n",
    "            ts = int(row[4].timestamp())\n",
    "        except:\n",
    "            continue\n",
    "        meta[\"msgs_ts_processed\"] += 1\n",
    "\n",
    "        for token in COVID_WORDS:\n",
    "            if token in msg:\n",
    "                meta[\"covid_tokens_found\"] += 1\n",
    "                covid_token_usage[token].append(ts)\n",
    "                refs = covid_token_refs[token]\n",
    "                for word in msg.split(\" \"):\n",
    "                    refs[word] += 1\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "with open(\"covid_tokens.pkl\", \"rb\") as f:\n",
    "    covid_token_usage_saved, covid_token_refs_saved = pickle.load(f)\n",
    "with open(\"covid_meta.pkl\", \"rb\") as f:\n",
    "    meta_saved = pickle.load(f)\n",
    "meta_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 71%\n",
    "meta_saved[\"msgs_ts_processed\"] / meta_saved[\"msgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.014%\n",
    "meta_saved[\"covid_tokens_found\"] / meta_saved[\"msgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing that interesting here\n",
    "for token, cntr in covid_token_refs_saved.items():\n",
    "    print(token)\n",
    "    print(cntr.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = {\"token\": [], \"Date\": []}\n",
    "for token, usage_ts in covid_token_usage_saved.items():\n",
    "    for ts in usage_ts:\n",
    "        df_data[\"token\"].append(token)\n",
    "        df_data[\"Date\"].append(ts)\n",
    "df = pd.DataFrame(df_data)\n",
    "# Start at the end of 2019\n",
    "df = df[df[\"Date\"] > 1575158400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "sns.histplot(df, x=\"Date\", hue=\"token\", ax=ax).set_title(\"COVID Words\")\n",
    "_ = ax.set_xticklabels(\n",
    "    [datetime.datetime.fromtimestamp(ts).isoformat()[:10] for ts in ax.get_xticks()]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
