{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = psycopg2.connect(\n",
    "        user=\"postgres\",\n",
    "        password=os.environ.get(\"POSTGRES_PASS\", \"\"),\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"venmo\",\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "\n",
    "def reduce_graph(old_graph, f):\n",
    "    new_graph = nx.Graph()\n",
    "    for a, b, data in old_graph.edges(data=True):\n",
    "        if f(data):\n",
    "            new_graph.add_edge(a, b, **data)\n",
    "    return new_graph\n",
    "\n",
    "\n",
    "def find_coords(place, cache):\n",
    "    found = cache.get(place)\n",
    "    if found:\n",
    "        return (found.latitude, found.longitude)\n",
    "    location = geolocator.geocode(place)\n",
    "    if location is None:\n",
    "        return None\n",
    "    cache[place] = location\n",
    "    return (location.latitude, location.longitude)\n",
    "\n",
    "\n",
    "def parse_geo_tokens(geoparser, raw_msg):\n",
    "    msg = re.sub(r\"[^\\w\\d_\\- ]\", \"\", raw_msg).strip()\n",
    "    if len(msg) == 0:\n",
    "        return []\n",
    "    return geoparser.geoparse(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    LEAST(actor_user_id, recipient_id),\n",
    "    GREATEST(actor_user_id, recipient_id),\n",
    "    array_agg(id),\n",
    "    array_agg(created),\n",
    "    array_agg(message)\n",
    "FROM \n",
    "    transactions\n",
    "WHERE \n",
    "    created > '2020-03-10'\n",
    "GROUP BY \n",
    "    GREATEST(actor_user_id, recipient_id),\n",
    "    LEAST(actor_user_id, recipient_id)\n",
    "\"\"\"\n",
    "\n",
    "conn = connect()\n",
    "with conn.cursor(name=\"clusters\") as cursor:\n",
    "    cursor.itersize = 500\n",
    "    cursor.execute(query)\n",
    "    for i, (a, b, ids, createds, msgs) in enumerate(cursor):\n",
    "        if i % 1_000_000 == 0 and i != 0:\n",
    "            print(\"Checkpoint @\", i)\n",
    "            with open(\"cluster_graph.pkl\", \"wb\") as f:\n",
    "                pickle.dump(graph, f)\n",
    "        graph.add_edge(a, b, weight=len(ids), dates=createds, msgs=msgs)\n",
    "\n",
    "with open(\"cluster_graph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(graph, f)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cluster_graph.pkl\", \"rb\") as f:\n",
    "    graph_saved = pickle.load(f)\n",
    "with open(\"user_id_to_loc.pkl\", \"rb\") as f:\n",
    "    user_id_to_loc_saved = pickle.load(f)\n",
    "with open(\"geo_cache.pkl\", \"rb\") as f:\n",
    "    geo_cache = pickle.load(f)\n",
    "known_user_ids = set(user_id_to_loc_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_least_two(data):\n",
    "    return len(data[\"dates\"]) >= 3\n",
    "\n",
    "\n",
    "ng = reduce_graph(graph_saved, at_least_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graphs = nx.connected_components(graph_saved)\n",
    "sub_graph_sizes = []\n",
    "for sg in sub_graphs:\n",
    "    if sg & known_user_ids:\n",
    "        print(sg)\n",
    "    #         cluster = ng.subgraph(sg)\n",
    "    #         print(cluster.edges.data())\n",
    "    # sub_graph_sizes.append(len(sg))\n",
    "# plt.hist(sub_graph_sizes)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mordecai import Geoparser\n",
    "\n",
    "geo = Geoparser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graphs = nx.connected_components(graph_saved)\n",
    "for sg in sub_graphs:\n",
    "    if len(sg) > 100:\n",
    "        continue\n",
    "    cluster = ng.subgraph(sg)\n",
    "    msgs = []\n",
    "    for _, _, edge_msgs in cluster.edges.data(\"msgs\"):\n",
    "        msgs.extend(edge_msgs)\n",
    "    locs = []\n",
    "    for m in msgs:\n",
    "        locs.extend(parse_geo_tokens(geo, m))\n",
    "    places = [(item[\"token\", item[\"geo\"][\"admin1\"]) for item in locs if \"geo\" in item]\n",
    "    if len(places) > 0:\n",
    "        print(places)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
