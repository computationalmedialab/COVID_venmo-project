{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import geoplot.crs as gcrs\n",
    "import geoplot as gplt\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/geopy/geopy\n",
    "#  $ pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"sshh12/venmo-research\")\n",
    "\n",
    "if os.path.isfile(\"geo_cache.pkl\"):\n",
    "    print(\"Using existing geo cache\")\n",
    "    with open(\"geo_cache.pkl\", \"rb\") as f:\n",
    "        geo_cache = pickle.load(f)\n",
    "else:\n",
    "    geo_cache = {}\n",
    "\n",
    "\n",
    "def find_coords(place, cache):\n",
    "    found = cache.get(place)\n",
    "    if found:\n",
    "        return (found.latitude, found.longitude)\n",
    "    location = geolocator.geocode(place)\n",
    "    if location is None:\n",
    "        return None\n",
    "    cache[place] = location\n",
    "    return (location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = psycopg2.connect(\n",
    "        user=\"postgres\",\n",
    "        password=os.environ.get(\"POSTGRES_PASS\", \"\"),\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"venmo\",\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "\n",
    "def get_count(query, cn):\n",
    "    q = \"SELECT COUNT(*) FROM \" + query\n",
    "    cur = cn.cursor()\n",
    "    cur.execute(q)\n",
    "    return cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Total Transactions: 135921927\n",
    "Total Users: 22066565\n",
    "Total Users w/facebook=true pic: 2479401\n",
    "Total Users w/peekyou data: 393499\n",
    "Total Users w/peekyou match: 19721\n",
    "Total Users w/facebook search results: 22897\n",
    "Total Users w/facebook profile (verified): 7079\n",
    "\"\"\"\n",
    "conn = connect()\n",
    "print(\"Total Transactions:\", get_count(\"transactions\", conn))\n",
    "print(\"Total Users:\", get_count(\"users\", conn))\n",
    "print(\n",
    "    \"Total Users w/facebook=true pic:\",\n",
    "    get_count(\"users WHERE picture_url LIKE '%%facebook=true'\", conn),\n",
    ")\n",
    "print(\n",
    "    \"Total Users w/peekyou data:\",\n",
    "    get_count(\"users WHERE peek_you_results is not null\", conn),\n",
    ")\n",
    "print(\n",
    "    \"Total Users w/peekyou match:\",\n",
    "    get_count(\n",
    "        \"users WHERE peek_you_results is not null and (peek_you_results ->> 'ResultsMatch') != '[]'\",\n",
    "        conn,\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"Total Users w/facebook search results:\",\n",
    "    get_count(\"users WHERE facebook_results is not null\", conn),\n",
    ")\n",
    "print(\n",
    "    \"Total Users w/facebook profile (verified):\",\n",
    "    get_count(\"users WHERE facebook_profile is not null\", conn),\n",
    ")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_id_to_loc = {}\n",
    "\n",
    "\n",
    "def save():\n",
    "    print(\"Saving checkpoint...\")\n",
    "    with open(\"user_id_to_loc.pkl\", \"wb\") as f:\n",
    "        pickle.dump(user_id_to_loc, f)\n",
    "    with open(\"geo_cache.pkl\", \"wb\") as f:\n",
    "        pickle.dump(geo_cache, f)\n",
    "\n",
    "\n",
    "conn = connect()\n",
    "with conn.cursor(name=\"social_media_exploration\") as cursor:\n",
    "    cursor.itersize = 2000\n",
    "    cursor.execute(\n",
    "        \"SELECT id, facebook_profile FROM users WHERE facebook_profile is not null\"\n",
    "    )\n",
    "    for i, (id_, facebook_profile) in enumerate(cursor):\n",
    "        if i % 500 == 0 and i != 0:\n",
    "            save()\n",
    "        info = facebook_profile[\"info\"]\n",
    "        lives_in = [item for item in info if item.startswith(\"Lives\")]\n",
    "        from_ = [item for item in info if item.startswith(\"From \")]\n",
    "        if len(lives_in) > 0:\n",
    "            loc = lives_in[0].replace(\"Lives in \", \"\")\n",
    "        elif len(from_) > 0:\n",
    "            loc = from_[0].replace(\"From  \", \"\")\n",
    "        else:\n",
    "            continue\n",
    "        coords = find_coords(loc, geo_cache)\n",
    "        if coords is None:\n",
    "            continue\n",
    "        lat, lng = coords\n",
    "        user_id_to_loc[id_] = (lat, lng, loc)\n",
    "save()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_id_to_loc.pkl\", \"rb\") as f:\n",
    "    user_id_to_loc_saved = pickle.load(f)\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "contiguous_usa = gpd.read_file(gplt.datasets.get_path(\"contiguous_usa\"))\n",
    "usa = world[world.name == \"United States of America\"]\n",
    "\n",
    "df_data = {\"id\": [], \"lat\": [], \"lng\": [], \"loc\": []}\n",
    "for key, (lat, lng, loc) in user_id_to_loc_saved.items():\n",
    "    df_data[\"id\"].append(key)\n",
    "    df_data[\"lat\"].append(lat)\n",
    "    df_data[\"lng\"].append(lng)\n",
    "    df_data[\"loc\"].append(loc)\n",
    "df = pd.DataFrame(df_data)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lng, df.lat))\n",
    "\n",
    "usa_gdf = gdf.loc[gdf.within(usa.iloc[0][\"geometry\"])].copy()\n",
    "\n",
    "# 96 % in USA\n",
    "print(round(len(usa_gdf) / len(gdf) * 100), \"% in USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gplt.webmap(contiguous_usa, projection=gcrs.WebMercator(), figsize=(16, 16))\n",
    "_ = gplt.pointplot(usa_gdf, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
